{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative Adversarial Networks (GANs)\n",
    "\n",
    "GANs is a method for training generative models that was proposed in 2014 by Goodfellow et al. There are two neural networks in a GAN. One is called the generator which takes a random noise as input and outputs an image. The other is called the discriminator which is a binary classifier to classify whether an input image is a real image or a fake image generated by the generator. The goal of the generator is to generate images that can fool the discriminator into thinking the images are real.\n",
    "\n",
    "This iterative process of generator trying to fool the discriminator and the discriminator trying to correctly classify real vs. fake as a minimax game:\n",
    "$$\\underset{G}{\\text{minimize}}\\; \\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "where $z \\sim p(z)$ are random noise vectors,  $G(z)$ are the fake images generated by the generator $G$, $D$ is a probability of the input of the discriminator being real. In [Goodfellow et al.](https://arxiv.org/abs/1406.2661), they analyze this minimax game and show how it relates to minimizing the Jensen-Shannon divergence between the training data distribution and the generated samples from $G$.\n",
    "\n",
    "In practice, for the objective of the generator, instead of minimizing the following objection:\n",
    "$$\\underset{G}{\\text{minimize}}\\; \\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "We use a different objective for the generator: maximizing the probability of the disciminator being fooled. \n",
    "\n",
    "$$\\underset{G}{\\text{maximize}}\\; \\left[\\log \\left(D(G(z))\\right)\\right]$$\n",
    "\n",
    "This helps to allevaiate problems with the generator gradient vanishing when the discriminator is confident. This is the standard update used in most GAN papers, and was used in the original paper from [Goodfellow et al.](https://arxiv.org/abs/1406.2661). \n",
    "\n",
    "In this assignment, we will alternate the following updates:\n",
    "1. Update the generator ($G$) to maximize the probability of the discriminator making the incorrect choice on generated data:\n",
    "$$\\underset{G}{\\text{maximize}}\\;  \\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "2. Update the discriminator ($D$), to maximize the probability of the discriminator making the correct choice on real and generated data:\n",
    "$$\\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets ,utils\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "def show_images(images):\n",
    "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return \n",
    "\n",
    "def preprocess_img(x):\n",
    "    return 2 * x - 1.0\n",
    "\n",
    "def deprocess_img(x):\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def rel_error(x,y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def count_params(model):\n",
    "    \"\"\"Count the number of parameters in the current TensorFlow graph \"\"\"\n",
    "    param_count = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
    "    return param_count\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    " GANs are notoriously finicky with hyperparameters, and also require many training epochs. In order to make this assignment approachable without a GPU, we will be working on the MNIST dataset, which is 60,000 training and 10,000 test images. Each picture contains a centered image of white digit on black background (0 through 9). This was one of the first datasets used to train convolutional neural networks and it is fairly easy -- a standard CNN model can easily exceed 99% accuracy. \n",
    "\n",
    "To simplify our code here, we will use the PyTorch MNIST wrapper, which downloads and loads the MNIST dataset. See the [documentation](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) for more information about the interface. The default parameters will take 5,000 of the training examples and place them into a validation dataset. The data will be saved into a folder called `MNIST_data`. \n",
    "\n",
    "## Random Noise\n",
    "Generate uniform noise from -1 to 1 with shape `[batch_size, dim]`.\n",
    "\n",
    "Hint: use `torch.rand`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_noise(batch_size, dim):\n",
    "    \"\"\"\n",
    "    Generate a PyTorch Tensor of uniform random noise.\n",
    "\n",
    "    Input:\n",
    "    - batch_size: Integer giving the batch size of noise to generate.\n",
    "    - dim: Integer giving the dimension of noise to generate.\n",
    "    \n",
    "    Output:\n",
    "    - A PyTorch Tensor of shape (batch_size, dim) containing uniform\n",
    "      random noise in the range (-1, 1).\n",
    "    \"\"\"\n",
    "    ###############\n",
    "    ##1st TO DO (4 points)\n",
    "    #################\n",
    "    noise=None\n",
    "  \n",
    "    return noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure noise is the correct shape and type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_sample_noise():\n",
    "    batch_size = 3\n",
    "    dim = 4\n",
    "    torch.manual_seed(231)\n",
    "    z = sample_noise(batch_size, dim)\n",
    "    np_z = z.cpu().numpy()\n",
    "    assert np_z.shape == (batch_size, dim)\n",
    "    assert torch.is_tensor(z)\n",
    "    assert np.all(np_z >= -1.0) and np.all(np_z <= 1.0)\n",
    "    assert np.any(np_z < 0.0) and np.any(np_z > 0.0)\n",
    "    print('All tests passed!')\n",
    "    \n",
    "test_sample_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start=0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 50000\n",
    "NUM_VAL = 5000\n",
    "\n",
    "NOISE_DIM = 100\n",
    "batch_size = 128\n",
    "\n",
    "mnist_train = dset.MNIST('./data/MNIST_data', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_train = DataLoader(mnist_train, batch_size=batch_size,\n",
    "                          sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "mnist_val = dset.MNIST('./data/MNIST_data', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_val = DataLoader(mnist_val, batch_size=batch_size,\n",
    "                        sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "\n",
    "\n",
    "imgs = loader_train.__iter__().next()[0].view(batch_size, 784).numpy().squeeze()\n",
    "show_images(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten\n",
    "\n",
    "Flatten makes each image in a batch as a one dimentional vector. Unflatten makes each one dimentional vector in a batch as an image, which you might want to use when implementing the convolutional generator. We also provide a weight initializer (and call it for you) that uses Xavier initialization instead of PyTorch's uniform default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "    \n",
    "class Unflatten(nn.Module):\n",
    "    \"\"\"\n",
    "    An Unflatten module receives an input of shape (N, C*H*W) and reshapes it\n",
    "    to produce an output of shape (N, C, H, W).\n",
    "    \"\"\"\n",
    "    def __init__(self, N=-1, C=128, H=7, W=7):\n",
    "        super(Unflatten, self).__init__()\n",
    "        self.N = N\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "    def forward(self, x):\n",
    "        return x.view(self.N, self.C, self.H, self.W)\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.ConvTranspose2d):\n",
    "        init.xavier_uniform(m.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU / GPU\n",
    "By default all code will run on CPU. GPUs are not needed for this assignment, but will help you to train your models faster. If you do want to run the code on a GPU, then change the `dtype` variable in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "#dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator\n",
    "We will use a discriminator inspired by the TensorFlow MNIST classification tutorial, which is able to get above 99% accuracy on the MNIST dataset fairly quickly. \n",
    "* Reshape into image tensor (Use Unflatten!)\n",
    "* 36 Filters, 4x4, Stride 1, Leaky ReLU(alpha=0.02)\n",
    "* Max Pool 2x2, Stride 2\n",
    "* 72 Filters, 4x4, Stride 1, Leaky ReLU(alpha=0.02)\n",
    "* Max Pool 2x2, Stride 2\n",
    "* Flatten\n",
    "* Fully Connected output size 1024, Leaky ReLU(alpha=0.02)\n",
    "* Fully Connected output size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dc_classifier():#mnist\n",
    "    \"\"\"\n",
    "    Build and return a PyTorch model for the DCGAN discriminator implementing\n",
    "    the architecture above.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        ###########################\n",
    "        #########2nd TO DO (10 points)###########\n",
    "        ###########################\n",
    "        \n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of parameters in your classifier as a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_dc_classifer(true_count=1223853):\n",
    "    model = build_dc_classifier()\n",
    "    cur_count = count_params(model)\n",
    "    if cur_count != true_count:\n",
    "        print(cur_count)\n",
    "        print('Incorrect number of parameters in generator. Check your achitecture.')\n",
    "    else:\n",
    "        print('Correct number of parameters in generator.')\n",
    "\n",
    "test_dc_classifer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator.\n",
    "See the document for documentation for [ConvTranspose2d](http://pytorch.org/docs/master/nn.html?highlight=convtranspose2d#torch.nn.ConvTranspose2d). \n",
    "\n",
    "* Fully connected of size 1500, ReLU\n",
    "* BatchNorm\n",
    "* Fully connected of size 7 x 7 x 120, ReLU\n",
    "* BatchNorm\n",
    "* Reshape into Image Tensor using Unflatten(), you should figure out the parameters of N,C,H and W.\n",
    "* 60 ConvTranspose2d filters of 4x4, stride 2,  padding=1, ReLU\n",
    "* BatchNorm\n",
    "* 1 ConvTranspose2d filter of 4x4, stride 2, padding=1, TanH\n",
    "* Should have a 28x28x1 image, reshape back into 784 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dc_generator(noise_dim=NOISE_DIM):#mnist\n",
    "    \"\"\"\n",
    "    Build and return a PyTorch model implementing the DCGAN generator using\n",
    "    the architecture described above.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        #########3rd TO DO (10 points)###########\n",
    "\n",
    "       \n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of parameters in your generator as a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_dc_generator(true_count=9108481):\n",
    "    model = build_dc_generator(4)\n",
    "    cur_count = count_params(model)\n",
    "    if cur_count != true_count:\n",
    "        print(cur_count)\n",
    "        print('Incorrect number of parameters in generator. Check your achitecture.')\n",
    "    else:\n",
    "        print('Correct number of parameters in generator.')\n",
    "\n",
    "test_dc_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Loss\n",
    "\n",
    "Compute the generator and discriminator loss. The generator loss is:\n",
    "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "and the discriminator loss is:\n",
    "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "Note that these are negated from the equations presented earlier as we will be *minimizing* these losses.\n",
    "\n",
    "**HINTS**: You should use the `bce_loss` function defined below to compute the binary cross entropy loss which is needed to compute the log probability of the true label given the logits output from the discriminator. Given a score $s\\in\\mathbb{R}$ and a label $y\\in\\{0, 1\\}$, the binary cross entropy loss is\n",
    "\n",
    "$$ bce(s, y) = y * \\log(s) + (1 - y) * \\log(1 - s) $$\n",
    "\n",
    "A naive implementation of this formula can be numerically unstable, so we have provided a numerically stable implementation for you below.\n",
    "\n",
    "You will also need to compute labels corresponding to real or fake and use the logit arguments to determine their size. Make sure you cast these labels to the correct data type using the global `dtype` variable, for example:\n",
    "\n",
    "\n",
    "`true_labels = Variable(torch.ones(size)).type(dtype)`\n",
    "\n",
    "Instead of computing the expectation, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bce_loss(input, target):\n",
    "    \"\"\"\n",
    "    Numerically stable version of the binary cross-entropy loss function.\n",
    "\n",
    "    As per https://github.com/pytorch/pytorch/issues/751\n",
    "    See the TensorFlow docs for a derivation of this formula:\n",
    "    https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
    "\n",
    "    Inputs:\n",
    "    - input: PyTorch Variable of shape (N, ) giving scores.\n",
    "    - target: PyTorch Variable of shape (N,) containing 0 and 1 giving targets.\n",
    "\n",
    "    Returns:\n",
    "    - A PyTorch Variable containing the mean BCE loss over the minibatch of input data.\n",
    "    \"\"\"\n",
    "    neg_abs = - input.abs()\n",
    "    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "    return loss.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(logits_real, logits_fake):\n",
    "    \"\"\"\n",
    "    Computes the discriminator loss described above.\n",
    "    \n",
    "    Inputs:\n",
    "    - logits_real: PyTorch Variable of shape (N,) giving scores for the real data.\n",
    "    - logits_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Variable containing (scalar) the loss for the discriminator.\n",
    "    \"\"\"\n",
    "    ##########4th TO DO (5 points)#############\n",
    "    true_labels = None\n",
    "    fake_labels = None\n",
    "    loss = None\n",
    "\n",
    "    return loss\n",
    "\n",
    "def generator_loss(logits_fake):\n",
    "    \"\"\"\n",
    "    Computes the generator loss described above.\n",
    "\n",
    "    Inputs:\n",
    "    - logits_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Variable containing the (scalar) loss for the generator.\n",
    "    \"\"\"\n",
    "    #-log(1 / (1 + exp(-x)))\n",
    "    #####5th TO DO (3 points)########\n",
    "    loss= None\n",
    "  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your generator and discriminator loss. You should see errors < 1e-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_discriminator_loss(logits_real, logits_fake, d_loss_true):\n",
    "    d_loss = discriminator_loss(Variable(torch.Tensor(logits_real)).type(dtype),\n",
    "                                Variable(torch.Tensor(logits_fake)).type(dtype)).data.cpu().numpy()\n",
    "    print(\"Maximum error in d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
    "\n",
    "test_discriminator_loss(answers['logits_real'], answers['logits_fake'],\n",
    "                        answers['d_loss_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator_loss(logits_fake, g_loss_true):\n",
    "    g_loss = generator_loss(Variable(torch.Tensor(logits_fake)).type(dtype)).data.cpu().numpy()\n",
    "    print(\"Maximum error in g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
    "\n",
    "test_generator_loss(answers['logits_fake'], answers['g_loss_true'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing our loss\n",
    "Make a function that returns an `optim.Adam` optimizer for the given model with a 2e-3 learning rate, beta1=0.6, beta2=0.9999. You'll use this to construct optimizers for the generators and discriminators for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_optimizer(model):\n",
    "    \"\"\"\n",
    "    Construct and return an Adam optimizer for the model with learning rate 2e-3,\n",
    "    beta1=0.5, and beta2=0.999.\n",
    "    \n",
    "    Input:\n",
    "    - model: A PyTorch model that we want to optimize.\n",
    "    \n",
    "    Returns:\n",
    "    - An Adam optimizer for the model with the desired hyperparameters.\n",
    "    \"\"\"\n",
    "    #########6th TO DO (3 points)###############\n",
    "    optimizer = None\n",
    "  \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a GAN!\n",
    "\n",
    "We provide you the main training loop... you won't need to change this function, but we encourage you to read through and understand it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, show_every=250, \n",
    "              batch_size=128, noise_size=100, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Train a GAN!\n",
    "    \n",
    "    Inputs:\n",
    "    - D, G: PyTorch models for the discriminator and generator\n",
    "    - D_solver, G_solver: torch.optim Optimizers to use for training the\n",
    "      discriminator and generator.\n",
    "    - discriminator_loss, generator_loss: Functions to use for computing the generator and\n",
    "      discriminator loss, respectively.\n",
    "    - show_every: Show samples after every show_every iterations.\n",
    "    - batch_size: Batch size to use for training.\n",
    "    - noise_size: Dimension of the noise to use as input to the generator.\n",
    "    - num_epochs: Number of epochs over the training dataset to use for training.\n",
    "    \"\"\"\n",
    "    iter_count = 0\n",
    "    t1=time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        for x, _ in loader_train:\n",
    "            t2=time.time()\n",
    "            if len(x) != batch_size:\n",
    "                continue\n",
    "            D_solver.zero_grad()\n",
    "            real_data = Variable(x).type(dtype)\n",
    "            real_data=real_data.view(batch_size,1,784)\n",
    "            logits_real = D(2* (real_data - 0.5)).type(dtype)\n",
    "\n",
    "            g_fake_seed = Variable(sample_noise(batch_size, noise_size)).type(dtype)\n",
    "            fake_images = G(g_fake_seed)\n",
    "            fake_images=fake_images.detach()\n",
    "            \n",
    "            logits_fake = D(fake_images.view(batch_size, 1, 784))\n",
    "\n",
    "            d_total_error = discriminator_loss(logits_real, logits_fake)\n",
    "            d_total_error.backward()        \n",
    "            D_solver.step()\n",
    "\n",
    "            G_solver.zero_grad()\n",
    "            g_fake_seed = Variable(sample_noise(batch_size, noise_size)).type(dtype)\n",
    "            fake_images = G(g_fake_seed)\n",
    "\n",
    "            gen_logits_fake = D(fake_images.view(batch_size, 1, 784))\n",
    "            g_error = generator_loss(gen_logits_fake)\n",
    "            g_error.backward()\n",
    "            G_solver.step()\n",
    "\n",
    "            if (iter_count % show_every == 0):\n",
    "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,d_total_error.data[0],g_error.data[0]))\n",
    "                imgs_numpy = fake_images.data.cpu().numpy()\n",
    "                show_images(imgs_numpy[0:16])\n",
    "                plt.show()\n",
    "                print('total time: %.2f'%(time.time()-t1))\n",
    "                print('100 iter time: %.2f'%(time.time()-t2))\n",
    "                print()\n",
    "            iter_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would takes about 1 hour on one cpu. In the iterations in the low 100s you should see black backgrounds, fuzzy shapes as you approach iteration 1000, and decent shapes, about half of which will be sharp and clearly recognizable as we pass 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the discriminator\n",
    "D_DC = build_dc_classifier().type(dtype) \n",
    "D_DC.apply(initialize_weights)\n",
    "# Make the generator\n",
    "G_DC = build_dc_generator().type(dtype)\n",
    "G_DC.apply(initialize_weights)\n",
    "# Use the function you wrote earlier to get optimizers for the Discriminator and the Generator\n",
    "D_DC_solver = get_optimizer(D_DC)\n",
    "G_DC_solver = get_optimizer(G_DC)\n",
    "t1=time.time()\n",
    "print('start training')\n",
    "# Run it!\n",
    "run_a_gan(D_DC, G_DC, D_DC_solver, G_DC_solver, discriminator_loss, generator_loss, num_epochs=5)\n",
    "print(time.time()-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inline Question\n",
    "1.Exaplain how the ditribution of images change through iterations. (1 point)\n",
    "2.Explain why the loss of D cannot converge to around 0? \n",
    "What would happen if loss of D is very small and loss of G is very large at the end of training? Is this a prefered situation for generating images that look real? (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7th TO DO: write your answer here (5 points) ######\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
