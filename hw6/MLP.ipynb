{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: \n",
    "\n",
    "# 1. Use the pretrained ResNet18 as feature extractor\n",
    "# 2. Save extracted features (data3d is just the combinatation of train/valid/test resnet18 data)\n",
    "# 3. Train MLP for image classification and video classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,sampler,Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import timeit\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "label_mat=scipy.io.loadmat('./data/q3_2_data.mat')\n",
    "label_train=label_mat['trLb']\n",
    "label_val=label_mat['valLb']\n",
    "\n",
    "class ActionDataset(Dataset):\n",
    "    \"\"\"Action dataset.\"\"\"\n",
    "\n",
    "    def __init__(self,  root_dir,labels=[], transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            labels(list): labels if images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.length=len(os.listdir(self.root_dir))\n",
    "        self.labels=labels\n",
    "    def __len__(self):\n",
    "        return self.length*3\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        folder=math.floor(idx/3)+1\n",
    "        imidx=idx%3+1\n",
    "        folder=format(folder,'05d')\n",
    "        imgname=str(imidx)+'.jpg'\n",
    "        img_path = os.path.join(self.root_dir,\n",
    "                                folder,imgname)\n",
    "        image = Image.open(img_path)\n",
    "        if len(self.labels)!=0:\n",
    "            Label=self.labels[math.floor(idx/3)][0]-1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if len(self.labels)!=0:\n",
    "            sample={'image':image,'img_path':img_path,'Label':Label}\n",
    "        else:\n",
    "            sample={'image':image,'img_path':img_path}\n",
    "        return sample\n",
    "\n",
    "\n",
    "data_transform = T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "image_dataset_train=ActionDataset(root_dir='./data/trainClips/',labels=label_train,transform=data_transform)\n",
    "\n",
    "image_dataloader_train = DataLoader(image_dataset_train, batch_size=256,\n",
    "                        shuffle=False, num_workers=4)\n",
    "image_dataset_val=ActionDataset(root_dir='./data/valClips/',labels=label_val,transform=data_transform)\n",
    "\n",
    "image_dataloader_val = DataLoader(image_dataset_val, batch_size=256,\n",
    "                        shuffle=False, num_workers=4)\n",
    "image_dataset_test=ActionDataset(root_dir='./data/testClips/',labels=[],transform=data_transform)\n",
    "\n",
    "image_dataloader_test = DataLoader(image_dataset_test, batch_size=256,\n",
    "                        shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lihan_huang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def extract(x):\n",
    "    resnet18.eval()\n",
    "    N, C, W, H = x.size()\n",
    "    feature = torch.zeros([N,512]).cuda()\n",
    "    def copy_data(m, i, o):\n",
    "        feature.copy_(o.data)\n",
    "    layer = resnet18._modules.get('avgpool')\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    resnet18(x)\n",
    "    h.remove()\n",
    "    return feature.cpu().numpy()\n",
    "    \n",
    "Train = np.empty([256,512])\n",
    "dataloader = image_dataloader_test\n",
    "# dataloader = image_dataloader_train\n",
    "# dataloader = image_dataloader_val\n",
    "for t, sample in enumerate(dataloader):\n",
    "    \n",
    "    x_var = Variable(sample['image'].cuda())    \n",
    "    feature = extract(x_var)\n",
    "\n",
    "    if t==0: \n",
    "        Train = feature\n",
    "    else:\n",
    "        Train = np.append(Train, feature, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = np.float32(Train)\n",
    "scipy.io.savemat('test-resnet18.mat', {'tstD':Train}, do_compression=True)\n",
    "# scipy.io.savemat('train-resnet18.mat', {'tstD':Train}, do_compression=True)\n",
    "# scipy.io.savemat('valid-resnet18.mat', {'tstD':Train}, do_compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,sampler,Dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import timeit\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "label_mat=scipy.io.loadmat('./label2d.mat')\n",
    "train_mat=scipy.io.loadmat('./train-resnet18.mat')\n",
    "valid_mat=scipy.io.loadmat('./valid-resnet18.mat')\n",
    "test_mat=scipy.io.loadmat('./test-resnet18.mat')\n",
    "\n",
    "feature_train = train_mat['trD']\n",
    "feature_valid = valid_mat['valD']\n",
    "feature_test = test_mat['tstD']\n",
    "\n",
    "label_train=label_mat['trLb'][:,0]\n",
    "label_valid=label_mat['valLb'][:,0]\n",
    "\n",
    "empty_mat = scipy.io.loadmat('./empty2d.mat')\n",
    "label_test = empty_mat['tstLb'][:,0]\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(feature_train), torch.from_numpy(label_train))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True, num_workers=4)\n",
    "valid = torch.utils.data.TensorDataset(torch.from_numpy(feature_valid), torch.from_numpy(label_valid))\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=64, shuffle=False, num_workers=4)\n",
    "test = torch.utils.data.TensorDataset(torch.from_numpy(feature_test), torch.from_numpy(label_test))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 10),\n",
    "              )\n",
    "\n",
    "mlp = mlp.type(gpu_dtype)\n",
    "mlp.cuda()\n",
    "\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataloader, num_epochs = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, sample in enumerate(dataloader):\n",
    "            x_var = Variable(sample[0].cuda())\n",
    "            y_var = Variable(sample[1].cuda().long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "\n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % 100 == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def check_accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() \n",
    "    for t, sample in enumerate(loader):\n",
    "        x_var = Variable(sample[0].cuda())\n",
    "        y_var = sample[1].cuda()\n",
    "        y_var=y_var.cpu()\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds.numpy() == y_var.numpy()).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 10\n",
      "t = 100, loss = 0.0858\n",
      "t = 200, loss = 0.0342\n",
      "t = 300, loss = 0.0280\n",
      "Starting epoch 2 / 10\n",
      "t = 100, loss = 0.0151\n",
      "t = 200, loss = 0.0093\n",
      "t = 300, loss = 0.0103\n",
      "Starting epoch 3 / 10\n",
      "t = 100, loss = 0.0087\n",
      "t = 200, loss = 0.0089\n",
      "t = 300, loss = 0.0121\n",
      "Starting epoch 4 / 10\n",
      "t = 100, loss = 0.0136\n",
      "t = 200, loss = 0.0019\n",
      "t = 300, loss = 0.0081\n",
      "Starting epoch 5 / 10\n",
      "t = 100, loss = 0.0004\n",
      "t = 200, loss = 0.0031\n",
      "t = 300, loss = 0.0000\n",
      "Starting epoch 6 / 10\n",
      "t = 100, loss = 0.0007\n",
      "t = 200, loss = 0.0013\n",
      "t = 300, loss = 0.0000\n",
      "Starting epoch 7 / 10\n",
      "t = 100, loss = 0.0002\n",
      "t = 200, loss = 0.0007\n",
      "t = 300, loss = 0.0005\n",
      "Starting epoch 8 / 10\n",
      "t = 100, loss = 0.0003\n",
      "t = 200, loss = 0.0009\n",
      "t = 300, loss = 0.0000\n",
      "Starting epoch 9 / 10\n",
      "t = 100, loss = 0.0000\n",
      "t = 200, loss = 0.0000\n",
      "t = 300, loss = 0.0005\n",
      "Starting epoch 10 / 10\n",
      "t = 100, loss = 0.0010\n",
      "t = 200, loss = 0.0000\n",
      "t = 300, loss = 0.0001\n",
      "Got 23295 / 23310 correct (99.94)\n",
      "Got 5929 / 6690 correct (88.62)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MultiMarginLoss().cuda()\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "torch.random.manual_seed(12345)\n",
    "\n",
    "mlp.apply(reset) \n",
    "mlp.train() \n",
    "train(mlp, loss_fn, optimizer,train_loader, num_epochs=10) \n",
    "mlp.eval()\n",
    "check_accuracy(mlp, train_loader)\n",
    "check_accuracy(mlp, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9810\n"
     ]
    }
   ],
   "source": [
    "def predict_on_test(model, loader):\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() \n",
    "    results=open('mlp2d.csv','w')\n",
    "    count=0\n",
    "    results.write('Id'+','+'Class'+'\\n')\n",
    "    for t, sample in enumerate(loader):\n",
    "        x_var = Variable(sample[0].cuda())\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.max(1)\n",
    "        for i in range(len(preds)):\n",
    "            results.write(str(count)+','+str(preds[i])+'\\n')\n",
    "            count+=1\n",
    "    results.close()\n",
    "    return count\n",
    "\n",
    "count=predict_on_test(mlp, test_loader)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 84.82% on Kaggle test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,sampler,Dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import timeit\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "label_mat=scipy.io.loadmat('./label3d.mat')\n",
    "data_mat=scipy.io.loadmat('./data3d.mat')\n",
    "\n",
    "feature_train = data_mat['trD']\n",
    "feature_valid = data_mat['valD']\n",
    "feature_test = data_mat['tstD']\n",
    "\n",
    "label_train=label_mat['trLb'][:,0]\n",
    "label_valid=label_mat['valLb'][:,0]\n",
    "\n",
    "empty_mat = scipy.io.loadmat('./empty3d.mat')\n",
    "label_test = empty_mat['tstLb'][:,0]\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(feature_train), torch.from_numpy(label_train))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid = torch.utils.data.TensorDataset(torch.from_numpy(feature_valid), torch.from_numpy(label_valid))\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(torch.from_numpy(feature_test), torch.from_numpy(label_test))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataloader, num_epochs = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, sample in enumerate(dataloader):\n",
    "            x_var = Variable(sample[0].cuda())\n",
    "            y_var = Variable(sample[1].cuda().long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "\n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % 32 == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def check_accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() \n",
    "    for t, sample in enumerate(loader):\n",
    "        x_var = Variable(sample[0].cuda())\n",
    "        y_var = sample[1].cuda()\n",
    "        y_var=y_var.cpu()\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds.numpy() == y_var.numpy()).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(512*3, 512*2),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512*2, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 10),\n",
    "              )\n",
    "\n",
    "mlp = mlp.type(gpu_dtype)\n",
    "mlp.cuda()\n",
    "\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 32, loss = 0.1689\n",
      "t = 64, loss = 0.0448\n",
      "t = 96, loss = 0.0367\n",
      "t = 128, loss = 0.0365\n",
      "t = 160, loss = 0.0386\n",
      "t = 192, loss = 0.0353\n",
      "t = 224, loss = 0.0072\n",
      "Starting epoch 2 / 5\n",
      "t = 32, loss = 0.0113\n",
      "t = 64, loss = 0.0066\n",
      "t = 96, loss = 0.0301\n",
      "t = 128, loss = 0.0032\n",
      "t = 160, loss = 0.0051\n",
      "t = 192, loss = 0.0059\n",
      "t = 224, loss = 0.0025\n",
      "Starting epoch 3 / 5\n",
      "t = 32, loss = 0.0018\n",
      "t = 64, loss = 0.0053\n",
      "t = 96, loss = 0.0020\n",
      "t = 128, loss = 0.0030\n",
      "t = 160, loss = 0.0016\n",
      "t = 192, loss = 0.0049\n",
      "t = 224, loss = 0.0022\n",
      "Starting epoch 4 / 5\n",
      "t = 32, loss = 0.0025\n",
      "t = 64, loss = 0.0013\n",
      "t = 96, loss = 0.0004\n",
      "t = 128, loss = 0.0031\n",
      "t = 160, loss = 0.0002\n",
      "t = 192, loss = 0.0031\n",
      "t = 224, loss = 0.0017\n",
      "Starting epoch 5 / 5\n",
      "t = 32, loss = 0.0000\n",
      "t = 64, loss = 0.0019\n",
      "t = 96, loss = 0.0000\n",
      "t = 128, loss = 0.0000\n",
      "t = 160, loss = 0.0048\n",
      "t = 192, loss = 0.0000\n",
      "t = 224, loss = 0.0056\n",
      "Got 7764 / 7770 correct (99.92)\n",
      "Got 2050 / 2230 correct (91.93)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MultiMarginLoss().cuda()\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=1e-4)\n",
    "torch.random.manual_seed(12345)\n",
    "\n",
    "mlp.apply(reset) \n",
    "mlp.train() \n",
    "train(mlp, loss_fn, optimizer,train_loader, num_epochs=5) \n",
    "mlp.eval()\n",
    "check_accuracy(mlp, train_loader)\n",
    "check_accuracy(mlp, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3270\n"
     ]
    }
   ],
   "source": [
    "def predict_on_test3d(model, loader):\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() \n",
    "    results=open('mlp3d.csv','w')\n",
    "    count=0\n",
    "    results.write('Id'+','+'Class'+'\\n')\n",
    "    for t, sample in enumerate(loader):\n",
    "        x_var = Variable(sample[0].cuda())\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.max(1)\n",
    "        for i in range(len(preds)):\n",
    "            results.write(str(count)+','+str(preds[i])+'\\n')\n",
    "            count+=1\n",
    "    results.close()\n",
    "    return count\n",
    "\n",
    "count=predict_on_test3d(mlp, test_loader)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83.88% on Kaggle test data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
